#!/bin/bash

# Set up CoNLL-2003 train/test/dev data
export data_name="arxiv"
export raw_data_dir="$DILATED_CNN_NER_ROOT/data/initial_setup/arxiv"
export data_files=( "data.train.bio" "data.dev.bio" "data.test.bio" )
# todo get this number automatically
export max_sent_len=1100
export process_script="$DILATED_CNN_NER_ROOT/src/preprocessing/tsv_to_tfrecords.py"

export data_dir="$DILATED_CNN_NER_ROOT/data/$data_name-w$filter_width-$embeddings_name"

echo "data_dir: $data_dir"

if [[ "$start_end" == "true" ]]; then
    export data_dir="$data_dir-start_end"
fi

if [[ "$predict_pad" == "true" ]]; then
    export data_dir="$data_dir-pred_pad"
fi

if [[ "$documents" == "true" ]]; then
    export data_dir="$data_dir-docs"
fi

export train_dir="$data_dir/data.train.bio"
echo $train_dir
export dev_dir="$data_dir/data.dev.bio"
echo $dev_dir
export test_dir="$data_dir/data.test.bio"
echo $test_dir
export maps_dir=$test_dir

export vocab_cutoff=4
export update_vocab_file="$DILATED_CNN_NER_ROOT/data/vocabs/${data_name}_cutoff_${vocab_cutoff}.txt"



